// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`tokenizer should emit token with type \`Unknown\` when tokenizing address if closing bracket is missing 1`] = `
[
  {
    "range": {
      "from": 0,
      "to": 3,
    },
    "raw": "[00",
    "type": "Unknown",
    "value": "[00",
  },
]
`;

exports[`tokenizer should emit token with type \`Unknown\` when tokenizing address if closing bracket is missing 2`] = `
[
  {
    "range": {
      "from": 0,
      "to": 3,
    },
    "raw": "[al",
    "type": "Unknown",
    "value": "[AL",
  },
]
`;

exports[`tokenizer should emit token with type \`Unknown\` when tokenizing address if closing bracket is missing 3`] = `
[
  {
    "range": {
      "from": 0,
      "to": 3,
    },
    "raw": "[Bl",
    "type": "Unknown",
    "value": "[BL",
  },
]
`;

exports[`tokenizer should emit token with type \`Unknown\` when tokenizing address if closing bracket is missing 4`] = `
[
  {
    "range": {
      "from": 0,
      "to": 3,
    },
    "raw": "[cL",
    "type": "Unknown",
    "value": "[CL",
  },
]
`;

exports[`tokenizer should emit token with type \`Unknown\` when tokenizing address if closing bracket is missing 5`] = `
[
  {
    "range": {
      "from": 0,
      "to": 4,
    },
    "raw": "[ DL",
    "type": "Unknown",
    "value": "[ DL",
  },
]
`;

exports[`tokenizer should emit token with type \`Unknown\` when tokenizing string if closing quote is missing 1`] = `
[
  {
    "range": {
      "from": 0,
      "to": 3,
    },
    "raw": "\\"\\\\\\"",
    "type": "Unknown",
    "value": "\\"\\\\\\"",
  },
]
`;

exports[`tokenizer should emit token with type \`Unknown\` when tokenizing string if closing quote is missing 2`] = `
[
  {
    "range": {
      "from": 0,
      "to": 4,
    },
    "raw": "\\"foo",
    "type": "Unknown",
    "value": "\\"FOO",
  },
  {
    "range": {
      "from": 5,
      "to": 8,
    },
    "raw": "bar",
    "type": "Unknown",
    "value": "BAR",
  },
  {
    "range": {
      "from": 8,
      "to": 9,
    },
    "raw": "\\"",
    "type": "Unknown",
    "value": "\\"",
  },
]
`;

exports[`tokenizer should remove invalid escape 1`] = `
[
  {
    "range": {
      "from": 0,
      "to": 7,
    },
    "raw": "\\"f\\\\o\\\\o\\"",
    "type": "String",
    "value": "foo",
  },
]
`;

exports[`tokenizer should remove invalid escape 2`] = `
[
  {
    "range": {
      "from": 0,
      "to": 7,
    },
    "raw": "\\"\\\\0\\\\u1\\"",
    "type": "String",
    "value": "0u1",
  },
]
`;

exports[`tokenizer should skip comment at the end of the line 1`] = `
[
  {
    "range": {
      "from": 0,
      "to": 4,
    },
    "raw": "done",
    "type": "Unknown",
    "value": "DONE",
  },
  {
    "range": {
      "from": 4,
      "to": 5,
    },
    "raw": ":",
    "type": "Colon",
    "value": ":",
  },
  {
    "range": {
      "from": 25,
      "to": 28,
    },
    "raw": "end",
    "type": "Unknown",
    "value": "END",
  },
]
`;

exports[`tokenizer should skip line with comment 1`] = `
[
  {
    "range": {
      "from": 20,
      "to": 23,
    },
    "raw": "end",
    "type": "Unknown",
    "value": "END",
  },
]
`;

exports[`tokenizer should skip whitespace 1`] = `
[
  {
    "range": {
      "from": 3,
      "to": 7,
    },
    "raw": "done",
    "type": "Unknown",
    "value": "DONE",
  },
  {
    "range": {
      "from": 7,
      "to": 8,
    },
    "raw": ":",
    "type": "Colon",
    "value": ":",
  },
  {
    "range": {
      "from": 11,
      "to": 14,
    },
    "raw": "end",
    "type": "Unknown",
    "value": "END",
  },
]
`;

exports[`tokenizer should tokenize address 1`] = `
[
  {
    "range": {
      "from": 0,
      "to": 2,
    },
    "raw": "[]",
    "type": "Address",
    "value": "",
  },
  {
    "range": {
      "from": 3,
      "to": 7,
    },
    "raw": "[00]",
    "type": "Address",
    "value": "00",
  },
  {
    "range": {
      "from": 7,
      "to": 11,
    },
    "raw": "[al]",
    "type": "Address",
    "value": "AL",
  },
  {
    "range": {
      "from": 12,
      "to": 19,
    },
    "raw": "[ Bl  ]",
    "type": "Address",
    "value": "BL",
  },
]
`;

exports[`tokenizer should tokenize comma 1`] = `
[
  {
    "range": {
      "from": 0,
      "to": 1,
    },
    "raw": ",",
    "type": "Comma",
    "value": ",",
  },
  {
    "range": {
      "from": 2,
      "to": 3,
    },
    "raw": ",",
    "type": "Comma",
    "value": ",",
  },
  {
    "range": {
      "from": 3,
      "to": 4,
    },
    "raw": ",",
    "type": "Comma",
    "value": ",",
  },
]
`;

exports[`tokenizer should tokenize digits 1`] = `
[
  {
    "range": {
      "from": 0,
      "to": 1,
    },
    "raw": "0",
    "type": "Digits",
    "value": "0",
  },
  {
    "range": {
      "from": 2,
      "to": 4,
    },
    "raw": "01",
    "type": "Digits",
    "value": "01",
  },
  {
    "range": {
      "from": 5,
      "to": 8,
    },
    "raw": "002",
    "type": "Digits",
    "value": "002",
  },
]
`;

exports[`tokenizer should tokenize register 1`] = `
[
  {
    "range": {
      "from": 0,
      "to": 2,
    },
    "raw": "al",
    "type": "Register",
    "value": "AL",
  },
  {
    "range": {
      "from": 3,
      "to": 5,
    },
    "raw": "Bl",
    "type": "Register",
    "value": "BL",
  },
  {
    "range": {
      "from": 6,
      "to": 8,
    },
    "raw": "cL",
    "type": "Register",
    "value": "CL",
  },
  {
    "range": {
      "from": 9,
      "to": 11,
    },
    "raw": "DL",
    "type": "Register",
    "value": "DL",
  },
]
`;

exports[`tokenizer should tokenize string 1`] = `
[
  {
    "range": {
      "from": 0,
      "to": 2,
    },
    "raw": "\\"\\"",
    "type": "String",
    "value": "",
  },
  {
    "range": {
      "from": 3,
      "to": 21,
    },
    "raw": "\\"this is a string\\"",
    "type": "String",
    "value": "this is a string",
  },
  {
    "range": {
      "from": 22,
      "to": 26,
    },
    "raw": "\\"\\\\\\"\\"",
    "type": "String",
    "value": "\\"",
  },
  {
    "range": {
      "from": 27,
      "to": 31,
    },
    "raw": "\\"\\\\n\\"",
    "type": "String",
    "value": "
",
  },
]
`;
